{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_H, PDF_W = 400, 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "I. [Papers](#papers) <br>\n",
    " 1. [Lyapunov_functions](#Lyapunov_functions)\n",
    " 2. [Attractor Networks](#attractor_networks_section)<br>\n",
    "  A. [Attractor Networks, (Mozer, 2009)](#attractor_networks_mozer) <br>\n",
    "  B. [Localist Attractor Networks, (Zemel, Mozer, 2001)](#localist_attractor_networks)<br>\n",
    "  C. [Dynamics of Discrete Time, Continuous State Hopfield Networks (Koiran, 1994)](#koiran_1994)<br>\n",
    "  D. [State-Denoised Recurrent Neural Networks (Mozer, 2018)](#mozer_rnn_denoise) <br>\n",
    " 3. [Restricted Boltzmann Machines (RBMs)](#rbm_papers) <br>\n",
    "  A. [Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations (Lee, 2009)](#conv_RBM) <br>\n",
    " 4. [Recurrent Back Propagation (RBP)](#RBP)<br>\n",
    "  A. [Generalization of Backpropagation to Recurrent and Higher Order Neural Networks (Pineda, 1988)](#rbp_pineda)  <br>\n",
    "  B. [Reviving and Improving Recurrent Back-Propagation (Liao, 2018)](#rbp_liao) <br>\n",
    "  \n",
    "II. [Concepts](#concepts)\n",
    " 1. [Log-likelihood](#log_likelihood)\n",
    " 2. [Negative Log-Likelihood (NLL)](#NLL)\n",
    " 3. [Restricted Boltzmann Machines (RBMs)](#rbm_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Papers <a class=\"anchor\" id=\"papers\"></a> \n",
    "[To Top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lyapunov Functions <a class=\"anchor\" id=\"Lyapunov_functions\"></a> \n",
    "[To Top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://vanscoy.github.io/docs/papers/taylor2018lyapunov.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://vanscoy.github.io/docs/papers/taylor2018lyapunov.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "#### Minimization Problem, $\\mathcal{P}$\n",
    "Consider a minimization problem:\n",
    "\n",
    "\\begin{equation} \\tag{$\\mathcal{P}$}\n",
    "   \\text{minimize}_{x \\in \\mathbb{R}^d} \\quad f(x),       \n",
    "\\end{equation}\n",
    "where $f : \\mathbb{R}^d \\rightarrow \\mathbb{R}$.\n",
    "\n",
    "#### Iterative Methods, $\\mathcal{M}$\n",
    "To solve $\\mathcal{P}$, consider methods that iteratively update their estimate of the optimizer using only gradient evaluations. One method for proving convergence of such methods is by finding a *Lyapunov function*.\n",
    "\n",
    "For example, to solve the optimization problem ($\\mathcal{P}$), consider a *first-order iterative fixed-step method* of the form:\n",
    "\n",
    "\\begin{align*} \\tag{$\\mathcal{M}$}\n",
    "y_k &= \\sum_{j=0}^N \\gamma_j x_{k-j} \\\\\n",
    "x_{k+1} &= \\sum_{j=0}^N \\beta_j x_{k-j} - \\alpha \\nabla f(y_k)\n",
    "\\end{align*}\n",
    "\n",
    "for $k \\ge 0$ where $\\alpha, \\beta_j, \\gamma_j$ are the (Fixed) step-sizes and $x_j \\in \\mathbb{R}^d$ for $j = -N, \\ldots, 0$ are the initial conditions. We call the constant $N \\ge 0$ the *degree* of the method.\n",
    "\n",
    "### Lyapunov Functions\n",
    "*Lyapunov functions* are one of the fundamental tools in control theory that can be used to *verify stability of a dynamical system*. \n",
    "\n",
    "A Lyapunov function can be interpreted as defining an \"energy\" that decreases *geometrically* with each iteration of the method, with an energy of zero corresponding to reaching the optimal solution of $\\mathcal{P}$. The existence of such an energy function provides a straightforward certificate of linear convergence for the iterative method.\n",
    "\n",
    "Consider applying method ($\\mathcal{M}$) to solve problem ($\\mathcal{P}$). Our goal is to find the smallest possible $0 \\le \\rho < 1$ such that $\\{x_k \\}$ converges linearly to the optimizer $x_*$ with rate $\\rho$. A *Lyapunov function* $\\mathcal{V}$ is a continuous function $\\mathcal{V}: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ that satisfies the following properties:\n",
    "\n",
    "1. (nonnegative) $\\mathcal{V}(\\xi) \\ge 0$ for all $\\xi$,\n",
    "2. (zero at fixed-point) $\\mathcal{V}(\\xi) = 0$ iff $\\xi = \\xi_*$,\n",
    "3. (radially unbounded) $\\mathcal{V}(\\xi) \\rightarrow \\infty$ as $||\\xi|| \\rightarrow \\infty$,\n",
    "4. (decreasing) $\\mathcal{V}(\\xi_{k+1}) \\le \\rho^2 \\mathcal{V}(\\xi_{k})$ for $k \\le N$,\n",
    "\n",
    "where $\\xi_k := (\\mathbf{x}_k, \\mathbf{g}_k, \\mathbf{f}_k)$ for the *state* of the system at iteration $k$. \n",
    "\n",
    "If we can find such a $\\mathcal{V}$, then it can be used to show that the state converges linearly to the fixed-point from any initial condition, where the rate of convergence depends on both $\\rho$ and the structure of $\\mathcal{V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Attractor Networks <a class=\"anchor\" id=\"attractor_networks_section\"></a> \n",
    "[To Top](#toc)\n",
    "\n",
    "## Section Table of Contents <a class=\"anchor\" id=\"attractor_networks_section_toc\"></a>\n",
    "A. [Attractor Networks (Mozer, 2009)](#attractor_networks_mozer) <br>\n",
    "B. [Localist Attractor Networks (Zemel, Mozer, 2001)](#localist_attractor_networks) <br>\n",
    "C. [Dynamics of Discrete Time, Continuous State Hopfield Networks (Koiran, 1994)](#koiran_1994)<br>\n",
    "D. [State-Denoised Recurrent Neural Networks (Mozer, 2018)](#mozer_rnn_denoise) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.A. Attractor Networks (Mozer, 2009) <a class=\"anchor\" id=\"attractor_networks_mozer\"></a> \n",
    "[To ToC](#attractor_networks_section_toc)\n",
    "- Mozer, Michael C. (2009) \n",
    "- http://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/reprints/Mozer2008.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"http://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/reprints/Mozer2008.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b6682e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"http://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/reprints/Mozer2008.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- An attractor network is a recurrent ANN whose dynamics cause the network state to converge to a fixed point.\n",
    " - I.e., given an input, the dynamics of the network will cause the state to evolve over time to a stable value, away from which the state will not wander.\n",
    " - The states to which the net might evolve are called _attractors_\n",
    "- Attractor dynamics are achieved by many neural network architectures\n",
    " - Hopfield networks \n",
    "   - http://140.116.215.51/course/2012/hopfield.pdf\n",
    "   - http://www.rctn.org/bruno/public/papers/hopfield84.pdf\n",
    " - Harmony networks\n",
    " - Boltzmann Machines\n",
    "   - https://www.cs.toronto.edu/~hinton/absps/cogscibm.pdf\n",
    " - Adaptive resonance networks\n",
    " - Recurrent back prop networks\n",
    "   - A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. Almeida, L.B. (1987)\n",
    "   - Generalization of backpropagation to recurrent and higher order neural networks. Pineda, F.J. (1987)\n",
    "   - https://papers.nips.cc/paper/67-generalization-of-back-propagation-to-recurrent-and-higher-order-neural-networks.pdf\n",
    "\n",
    " \n",
    "- To ensure attractor dynamics, the architecutre **requires** symmetry of connectivity\n",
    " - Symmetry: the conncetion weight from processing unit _A_ to unit _B_ must be the same as the weight from _B_ to _A_.\n",
    " - Given this restriction, the dynamics of the network can be characterized as performing local optimization--minimizing *energy*, or equivalently, maximizing *harmony*.\n",
    " \n",
    "- The **input** to an attractor net can either specify the initial state of the net, or it can provide *biases*--fixed input--to each unit.\n",
    " - **Biases** reshape the landscape such that the best-matching attractor has maximum harmony, and is likely to be found for a wide range of initial network states.\n",
    " \n",
    "- Knowledge of attractor states is distributed over the connectivity pattern of the entire network - as a result, spurious (undesired) and ill-conditioned (e.g., very narrow) attractor basins may exist.\n",
    " - Solution: Localist Attractor Networks (see Zemel & Mozer, 2001)\n",
    " - LANs consist of a set of *state units* and a set of *attractor units* (one per unit). Each attractor unit draws the state toward its attractor, with the attractors closer to the state having a greater influence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B. Localist Attractor Networks (Zemel, Mozer, 2001) <a class=\"anchor\" id=\"localist_attractor_networks\"></a> \n",
    "[To ToC](#attractor_networks_section_toc)\n",
    "- Zemel, Richard S., Mozer, Michael C. (2001)\n",
    "- http://www.cs.utoronto.ca/pub/zemel/Papers/lanNC.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"http://www.cs.utoronto.ca/pub/zemel/Papers/lanNC.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b6685f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"http://www.cs.utoronto.ca/pub/zemel/Papers/lanNC.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Attractor networks map an input space (usually continuous) to a sparse output space.\n",
    "- Initial state of the attractor net is determined by the input pattern\n",
    " - Over time the state is drawn to one of a predefined set of states (the attractors)\n",
    "- Often used for **pattern completion**\n",
    "- Pattern completion can be accomplished with other methods -- e.g., nearest-neighbor classification\n",
    " - Attractor networks have benefits over other approaches:\n",
    "   1. Attractors can be characterized by compositional structure - this structure can be encoded implicitly in the attractor network.\n",
    "   2. Attractor networks have some degree of biological plausibility\n",
    "   3. In most formulations, the dynamics can be characterized by gradient descent in an energy landscale, allowing one to partition the output space into attractor basins. In many domains, the energy landscape and the corresponding structure of the attractor basins are key to obtaining desirable behavior. E.g., basins can be sculpted based on the recent history of the network (**priming**) and the arrangement of attractors in the space (**gang effects**).\n",
    "- **Priming** - a network is faster to land at an attractor if it has recently visited the same attractor. Achieved by broadening and deepening attractor basins *as they are visited*. This mechanism allows modelers to account for a ubiquitous property of human behavior: people are faster to perceive a stimulus if they have recently experienced the same or a closely related stimulus.\n",
    "- **Gang Effects** - the strength or pull of an attractor is influenced by other attractors in its neighborhood. \n",
    "\n",
    "- Training attractor networks is notoriously tricky. Why?\n",
    " - Training procedures are **CPU intensive**\n",
    " - **Spurious attractors** form\n",
    " - **Ill-conditioned attractor basins**\n",
    "\n",
    "- No known training procdure exists that can robustly translate an arbitrary specification of an attractor landscape into a set of weights.\n",
    " - Due to the fact that each connection participates in the specification of multiple attractors; **thus, knowledge in the net is distributed over connections**. \n",
    " \n",
    "### Localized Attractor Network\n",
    "#### Benefits\n",
    "1. Trivial procedure for devising architecture given an attractor landscape\n",
    "2. Spurious attractors are eliminated\n",
    "3. An attractor can be primed by adjusted a single parameter of the model\n",
    "4. Achieved gang effects\n",
    "5. Model parameters have a clear mathematical interpretation, which clarifies how the parameters control the qualitative behavior of the model (e.g., the magnitude of gang effects)\n",
    "6. Proofs of convergence and stability\n",
    "\n",
    "#### Structure\n",
    "- Consists of a set of _n_ state units and _m_ attractor units.\n",
    "- Parameters associated with an attractor unit _i_ encode the center in state-space of its attractor basin, denoted $w_i$, and its strength, denoted $\\pi _i$.\n",
    "- The activity of an attractor at time $t$, $q_i(t)$, reflects the normalized distance from its center to the current state, $y(t)$, weighted by its strength:\n",
    "\n",
    "$$ q_i(t) = \\frac{\\pi_i g(y(t), w_i, \\sigma(t))}{\\sum_j \\pi_j g(y(t), w_j, \\sigma(t))}$$\n",
    "\n",
    "$$ g(y, w, \\sigma) = exp(-|y - w|^2 / 2\\sigma^2) $$\n",
    "\n",
    ". . . \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.C. Dynamics of Discrete Time, Continuous State Hopfield Networks (Koiran, 1994) <a class=\"anchor\" id=\"koiran_1994\"></a> \n",
    "[To ToC](#attractor_networks_section_toc)\n",
    "\n",
    "- Koiran, Pascal (1994)\n",
    "- https://sci-hub.tw/10.1162/neco.1994.6.3.459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://dabamirror.sci-hub.tw/4428/cffc2674381d0fdb7b2fbecdd57498f5/koiran1994.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668630>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://dabamirror.sci-hub.tw/4428/cffc2674381d0fdb7b2fbecdd57498f5/koiran1994.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "**1**. Any trajectory converges to a fixed point for the *sequential iteration mode*\n",
    "\n",
    "**2**. Any trajectory converges to a cycle of length 2 or a fixed point for the *parallel* iteration mode.\n",
    "\n",
    "More specifically,\n",
    "- Discrete time, discrete state Hopfield network dynamics are driven by an energy function. This allows the length of a limit cycle to be bounded: the parallel iteration has cycles of length 1 or 2 only, and the sequential iteration has only fixed points. These results describe completely the asymptotic behavior of the network, since any trajectory enters a limit cycle after a transient period.\n",
    "\n",
    "- Discrete time, continuous state Hopfield networks are also driven by an energy function. However, a trajectory will generally **not** enter a cycle, so that the discrete-case case argument does not apply and the question of the convergence to a cycle arises.\n",
    "\n",
    "The key contribution of this paper is that is provides mathematical proofs for the statements above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 Math: Preliminaries\n",
    "\n",
    "#### State Update\n",
    "Consider a network of $n$ interconnected neurons, whose states $x_1, \\ldots, x_n$ belong to $[-1, 1]$. The transition function of neuron $i$ is $x_i \\mapsto f(A_i)$, where $A_i$ is the activation of neuron $i$, defined by:\n",
    "\n",
    "$$ A_i (x) = \\sum_{j=1}^n w_{ij}x_j - b_i$$\n",
    "\n",
    "where $b_i$ is the threshold of neuron $i$, and $w_{ij}$ is the weight of the connection between neurons $i and j$. Note, $b = (b_i)_{i \\le i \\le n}$ is the vector of thresholds. \n",
    "\n",
    "**N.B.** The matrix of weights $W = (w_{ij})$ is assumed to be **symmetric**, with a *nonnegative diagonal*. \n",
    "\n",
    "#### Activation Function, $f$\n",
    "$f$ is continuous, strictly increasing on an interval $[\\alpha, \\beta] \\quad (\\alpha < \\beta \\text{ and, possibly, } \\alpha = -\\infty \\text{ or } \\beta = +\\infty)$, and constant outside\n",
    "\\begin{align*}\n",
    "\\forall x \\le \\alpha, f(x) &= -1 \\\\\n",
    "\\forall x \\ge \\beta, f(x) &= +1 \\\\\n",
    "\\end{align*}\n",
    "If $a = -\\infty$ or $\\beta = +\\infty$, we ask that $\\lim_{x\\rightarrow \\pm \\infty} f(x) = \\pm 1$.\n",
    "\n",
    "$f$ may be piecewise $C^1$. In short, \n",
    "> A continuously differentiably function $f(x)$ is a function whose derivative function $f^\\prime(x)$ is also continuous at the point in question.\n",
    "\n",
    "- See [C^k notation](http://mathworld.wolfram.com/C-kFunction.html) or [smoothness](https://en.wikipedia.org/wiki/Smoothness) for more detailed discussion.\n",
    "\n",
    "#### Parallel and Sequential Iteration\n",
    "In *parallel iteration*, all neurons change state simultaneously: for $t \\in N$ and $1 \\le i \\le n$:\n",
    "\n",
    "$$ x_i(t+1) = f(A_i(t))$$\n",
    "\n",
    "In *sequential iteration*, neurons are updated in increasing order:\n",
    "$$ x_i(t+1/n) = f\\left(A_i \\left( \\frac{t+(i-1)}{n} \\right) \\right)$$\n",
    "\n",
    "Let $F$ be the function associated to a given iteration mode: \n",
    "- $F = P$ (parallel mode)\n",
    "- $F = S$ (sequential mode)\n",
    "\n",
    "**N.B.** Assuming a specific update order for sequential iterations is in fact not necessary. It is sufficient to update each neuron an infinite number of times. Note that these iteration modes have the same fixed points. \n",
    "\n",
    "#### Cycle Definition\n",
    "A cycle of length $T$ is a sequence $(y^0, \\ldots, y^{T-1})$ of distinct states such that $F(y^i) = y^{(i+1) \\text{ mod } T}$.\n",
    "\n",
    "We say that a sequence $(x(t))$ of iterates converges to this cycle if for any $i$ such that $0 \\le i \\le T - 1, \\lim_{t \\rightarrow +\\infty} x(Tt+i) = y^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 Math: Sequential Mode\n",
    "\n",
    "The existence of a [Lyapunov function](#Lyapunov_functions) for the sequential iteration and its consequence on the length of cycles are stated in Theorem 1 and Corollary 1.\n",
    "\n",
    "**N.B.** Theorem 2 and 4 are key results from this paper.\n",
    "\n",
    "---\n",
    "\n",
    "**Theorem 1**\n",
    ">Let $E$ be defined by <br>\n",
    "$$ E(x) = -x^TWx/2 + b^Tx + \\sum_{i=1}^n \\int_0^{x_i} f^{-1}(\\xi) d\\xi$$ <br>\n",
    "E is a *Lyapunov function* of the sequential iteration. I.e., <br>\n",
    "if $x(t+1/n) \\neq x(t), E(x(t+1/n)) < E(x(t))$.\n",
    "\n",
    "**Corollary 1**\n",
    ">Any cycle of the sequential iteration is a fixed point. <br>\n",
    "\n",
    "This is a standard consequence of the existence of a Lyapunov function. \n",
    "\n",
    "---\n",
    "\n",
    "**Theorem 2**\n",
    ">Assume the hypothesis (H) is true: the network has a finite number of fixed points. Then under this hypothesis, the sequential iteration converges to a fixed point from any starting point $x^0 \\in [-1, 1]^n$.\n",
    "\n",
    "- This theorem is a general result on dynamic systems driven by a Lyapunov function: the specific form of the iterated function or of the energy function is not important. \n",
    "\n",
    "---\n",
    "\n",
    "**Theorem 4**\n",
    ">When $f$ is piecewise $C^1$, the network has a finite number of fixed points for $(W, b)$ in an open dense set.\n",
    "\n",
    "Definitions:\n",
    "- **Closed Set** ([Springer](https://link.springer.com/chapter/10.1007/978-1-84628-627-8_4)) : a subset of a metric space that includes all of its boundary\n",
    "- **Open Set** ([Springer](https://link.springer.com/chapter/10.1007/978-1-84628-627-8_4)): a subset that contains no point of its boundary\n",
    "\n",
    "  - E.g., (-1, 1) is open; [-1, 1] is closed. \n",
    "\n",
    "- **Dense Set** ([wiki](https://en.wikipedia.org/wiki/Dense_set)):\n",
    "> a subset $A$ of a topological space $X$ is called dense (in $X$) if every point $x$ in $X$ either belongs to $A$ or is a limit point of $A$; that is, the closure of $A$ is constituting the whole set $X$.\n",
    "\n",
    "- **Compact Space** ([wiki](https://en.wikipedia.org/wiki/Compact_space))\n",
    ">In mathematics, and more specifically in general topology, compactness is a property that generalizes the notion of a subset of Euclidean space being closed (that is, containing all its limit points) and bounded (that is, having all its points lie within some fixed distance of each other). Examples include a closed interval, a rectangle, or a finite set of points. This notion is defined for more general topological spaces than Euclidean space in various ways.<br><br>\n",
    "One such generalization is that a topological space is sequentially compact if every infinite sequence of points sampled from the space has an infinite subsequence that converges to some point of the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 Math: Parallel Mode\n",
    "**Corollary 2**\n",
    ">Any cycle of the parallel iteration is of length 1 or 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.D. State-Denoised Recurrent Neural Networks (Mozer, 2018) <a class=\"anchor\" id=\"mozer_rnn_denoise\"></a> \n",
    "[To ToC](#mozer_rnn_denoise)\n",
    "\n",
    "- Mozer, Michael C., et al (2018)\n",
    "- https://arxiv.org/abs/1805.08394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://arxiv.org/pdf/1805.08394.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668668>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://arxiv.org/pdf/1805.08394.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Restricted Boltzman Machines (RBMs) <a class=\"anchor\" id=\"rbm_papers\"></a> \n",
    "[To Top](#toc)\n",
    "\n",
    "## Section Table of Contents <a class=\"anchor\" id=\"rbm_section_toc\"></a>\n",
    "A. [Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations](#conv_RBM) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.A. Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations <a class=\"anchor\" id=\"conv_RBM\"></a> \n",
    "[To ToC](#rbm_section_toc)\n",
    "- Lee, et al. (2009)\n",
    "- https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recurrent Back Propagation (RBP) <a class=\"anchor\" id=\"RBP\"></a> \n",
    "[To Top](#toc)\n",
    "\n",
    "## Section Table of Contents <a class=\"anchor\" id=\"rbp_section_toc\"></a>\n",
    "A. [Generalization of Backpropagation to Recurrent and Higher Order Neural Networks](#rbp_pineda) <br>\n",
    "B. [Reviving and Improving Recurrent Back-Propagation](#rbp_liao) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.A. Generalization of Backpropagation to Recurrent and Higher Order Neural Networks (Pineda, 1988) <a class=\"anchor\" id=\"rbp_pineda\"></a> \n",
    "[To ToC](#rbp_section_toc)\n",
    "- FJ Pineda (1988)\n",
    "- https://papers.nips.cc/paper/67-generalization-of-back-propagation-to-recurrent-and-higher-order-neural-networks.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://papers.nips.cc/paper/67-generalization-of-back-propagation-to-recurrent-and-higher-order-neural-networks.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b6687f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://papers.nips.cc/paper/67-generalization-of-back-propagation-to-recurrent-and-higher-order-neural-networks.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.B  Reviving and Improving Recurrent Back-Propagation (Liao, 2018) <a class=\"anchor\" id=\"rbp_liao\"></a> \n",
    "[To ToC](#rbp_section_toc)\n",
    "- Liao, et al. (2018)\n",
    "- http://xaqlab.com/wp-content/uploads/2018/07/RecurrentBackprop_IMCL.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"http://xaqlab.com/wp-content/uploads/2018/07/RecurrentBackprop_IMCL.pdf#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668780>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"http://xaqlab.com/wp-content/uploads/2018/07/RecurrentBackprop_IMCL.pdf#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Concepts <a class=\"anchor\" id=\"concepts\"></a> \n",
    "[To Top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log Likelihood <a id='log_likelihood'></a>\n",
    "**TL;DR** The log likelihood is used because a probability distributions logarithmic form is easier to differentiate and we are guaranteed that the \n",
    "\n",
    "Consider the Gaussian probability distribution,\n",
    "\n",
    "$$ P(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left(- \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) $$\n",
    "From [Probability concepts explained: Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1):\n",
    "> The above expression for the total probability is actually quite a pain to differentiate, so **it is almost always simplified by taking the natural logarithm of the expression**. This is absolutely fine because **the natural logarithm is a monotonically increasing function**. This means that if the value on the x-axis increases, the value on the y-axis also increases (see figure below). This is important because it ensures that **the maximum value of the log of the probability occurs at the same point as the original probability function**. Therefore we can work with the simpler log-likelihood instead of the original likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'log(x)')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.01, 1+0.01, 0.01)\n",
    "y = np.log(x)\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Log Likelihood Curve\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('log(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, see this [Math StackExchange Discussion](https://math.stackexchange.com/questions/892832/why-we-consider-log-likelihood-instead-of-likelihood-in-gaussian-distribution). To summarize:\n",
    "1. It is extremely useful for example when you want to calculate the joint likelihood for a set of independent and identically distributed points.\n",
    "2. Also in the case of Gaussian, it allows you to avoid computation of the exponential.\n",
    "\n",
    "3. $\\ln x$ is a monotonically increasing function, thus log-likelihoods have the same relations of order as the likelihoods:\n",
    "\n",
    "$$ p(x | \\Theta_1) > p(x | \\Theta_2) \\Leftrightarrow \\ln p(x | \\Theta_1) > \\ln p(x | \\Theta_2)$$\n",
    "4. From a standpoint of computational complexity, you can imagine that first of all summing is less expensive than multiplication (although nowadays these are almost equal). But what is even more important, likelihoods would become very small and you will run out of your floating point precision very quickly, yielding an underflow. That's why it is way more convenient to use the logarithm of the likelihood. Simply try to calculate the likelihood by hand, using pocket calculator - almost impossible.\n",
    "\n",
    "5. Additionally in the classification framework you can simplify calculations even further. The relations of order will remain valid if you drop the division by $2$ and the $2\\ln(2\\pi)$ term. You can do that because these are class independent. Also, as one might notice if variance of both classes is the same $\\left(\\sum_1=\\sum_2\\right)$, then you can also remove the $\\ln\\left(\\det\\sum\\right)$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Negative Log-Likelihood (NLL) <a id='NLL'></a>\n",
    "The negative of the [log-likelihood](#log_likelihood) is used in machine learning simply because optimizers are setup to **minimize** the return value of a function. Taking the negative of the log-likelihood results in $-\\infty$ and 0 for input values of $0$ and $1$, respectively. Optimizing the negative log-likelihood finds the maximum likelihood estimates (MLEs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '-log(x)')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8XXWd//HXJ0mTtFmbvemW7itrSwsIlE2tyOZPREAWEUUZxRGdccbfzxkdR8cVHUWURVAWQUAYBAZFtrJTSKEsXem+Z2vTZqFJk3x+f5yTEkqb3ra5OTf3vp+Px3305p5z7/l8b9L3+Z7v2czdERGR5JcWdQEiItI/FPgiIilCgS8ikiIU+CIiKUKBLyKSIhT4IiIpQoEvfcbM/mpml0VdR18zs2YzGxs+/4OZff8gPuNkM9vQ4+dFZnZy+Py7ZnZnnxW87xqqzMzNLCPey5LEpMAfwMxsjZnVmFlOj9c+b2bz+mHZHwgpd/+Yu98Wh2W5mY3v68/dYxn7DHJ3z3X3VX25PHef5u7z+vIz+4KZXWRm1eFKbnO4Ej8h6rqkbyjwB74M4B+jLkIGPjP7OvDfwH8B5cAo4DfAOQfxWdqKSEAK/IHvp8A/mVnh3iaa2WQze9zMtprZMjM7v8e0YjN72Mx2mNmrZvZ9M3u+x/Rfmtn6cPoCMzsxfH0u8H+BT4c9wTfC1+eFWxhZZtZoZtN7fFapmb1rZmXhz2ea2cJwvhfN7PADbbiZpZnZt81srZnVmtntZlbQY/ql4bQGM/u3cIvo9INYzl63MMwsz8yeNrNfWSDLzH5mZuvCLa8bzGzwPj5zz1oyw/qbwuGemT3mnRJ+t43htLN7TCsI31cXtvXbZpYWTksP66k3s1XAx3tpYwHwPeDL7v6Au7e4+y53f9jd/zmc531bQXsZplpjZv9iZm8CLWEtf95jOb80s1/1qP2WcEtiY/j3l76vGuXQKfAHvmpgHvBPe04Ih3oeB+4CyoALgd+Y2bRwluuBFqACuCx89PQqcCRQFH7GfWaW7e5/I+gF3hMOdxzR803u3gY8EC6v2/nAM+5ea2ZHA7cCXwSKgRuBh8ws6wDb/tnwcQowFsgFfh22fSpB7/QzwDCgABh+gJ+/T2ZWDDwJvODuX/XgGiU/BiYSfGfjw+X9e4wfeTbwJ6AQeKhHOwYBDwN/J/gdXg380cwmhe+7jqBtY4E5wKXA5eG0LwBnAkcBM4Hzeln+cUA28D8x1rsvFxKsWAqBO4AzzCw/bEs6wd/BXeG8twEdBN/VUcBHgM8f4vKlFwr85PDvwNVmVrrH62cCa9z99+7e4e6vAfcD54X/+T4JfMfdW919McF/wN3c/U53bwjfey2QBUwiNnfx/sC/iPf+o38BuNHd57t7Zzju3wYcG3uTgSDMf+7uq9y9GfgWcEE4nHAe8LC7P+/u7QTfUV9dOKoSeAa4z92/DWBmRtCua9x9q7s3EawUL4jxM59390fdvZMgKLtXoscSrMh+5O7t7v4U8AhwYfg7/DTwLXdvcvc1wLXAJeF7zwf+293Xu/tW4Ie9LL8YqHf3jhjr3Zdfhct7193XAq8B54bTTgVa3f1lMysHPgZ8LdyaqAV+QezflxwEjbMlAXd/28weAf4VWNJj0mhgtpk19ngtgyBQSsPn63tM6/kcM/sGQY+rkiAs84GSGMt6ChhsZrOBLQS93u7e42jgMjO7usf8meFyDkQlsLbHz2sJ2lQeTtvdHndvNbOGA/z8ffk40Azc0OO1UmAIsCDIfgAMiHWIYkuP561AdrjiqgTWu3tXj+lrCbYeSgi+tz2/g+4tmfd9B3vMt6cGoMTMMg4x9Nfv8XP3iv923r/SHw0MAjb3+L7S9vJ+6UMK/OTxHYLe1LU9XltPMIzy4T1nDnuHHcAIYHn48sge008E/gU4DVjk7l1mto0gxGA/veVw/nsJ/rPXAI+Evd7uun7g7j84sCZ+wCaC4Og2iqBNNcBmemyNhGPpxYe4vG43A0OBR81srru3APXAu8A0d9/YR8uBoI0jzSytR+iPIvid1QO7CL6DxT2mdS9/Mz1+p+G0fXkJ2EnQG//zPuZpIVipdavYyzx7/l3cB1xrZiOATxAMHUHwN9AGlPTBVoXESEM6ScLdVwD3AF/t8fIjwEQzu8TMBoWPY8xsSjh08ADwXTMbYmaTCcZ/u+URhGcdkGFm/07Qw+9WA1R17yDch7sIhhw+w3s9OwgC80tmNjvc2ZljZh83s7xePivTzLJ7PNKBu4FrzGyMmeXy3n6FDoLQOsvMjjezTOA/eG9ltS/peywjs5d5vwIsAx4xs8FhGN8M/MLe2zE93Mw+up9l7s98gqD9Zvj7Oxk4C/hT+Du8F/hBuAN5NPB1oPtw2XuBr5rZCDMbSrAFuFfuvp1g2Ot6Mzs3/JsYZGYfM7OfhLMtJBiTLzKzCuBr+yve3esI9jH9Hljt7kvC1zcT7Je41szyLdgBP87M5hzQtyMHRIGfXL4H7D4mP+xRf4RgXHQTwbDBjwnG4iEIrYLw9TsIArQtnPYY8FeCnuRagt5fz83t+8J/G8zstb0V4+7dYVUZflb369UE492/BrYBKwh2vvZmEUEPuvtxOcGO3zuAZ4HVYY1Xh8tYFD7/E0FPtwmo7dG+vfnXPZbx1L5mDHfSXknwnfzFzLIJtohWAC+b2Q7gCWLf57Gv5bQT7ND9GEGP/jfApe6+NJzlaoLveBXwPMGK9dZw2s0Ev8c3CLb+HtjPsn5OsML4NsGKfj3B38iD4Sx3hJ+1hiCs74mxGXcBp/P+lT4EHYxMgq2TbQQr6WExfqYcBNMNUKSbmf0YqHD3ZDxbNhdoBCa4++qo6xGJgnr4KcyCY/QPD4dVZgFXcOiH5SUMMzsrHJrIAX4GvEXQOxVJSQr81JZHsJnfQjDeey3wl0gr6lvnEAxlbQImABe4NmklhWlIR0QkRaiHLyKSIhLqOPySkhKvqqqKugwRkQFjwYIF9e6+51n2e5VQgV9VVUV1dXXUZYiIDBhm1tsZ1O+jIR0RkRShwBcRSREKfBGRFKHAFxFJEQp8EZEUocAXEUkRCnwRkRQx4AO/q8v59VPv8OzyuqhLERFJaAM+8NPSjBufXcVTS2ujLkVEJKEN+MAHKM/PZsv2nVGXISKS0JIi8Cvys6lpUuCLiPQmKQK/LD+LGvXwRUR6lRSBX5GfTW1TG11dura/iMi+JEXgl+dn09HlNLS0R12KiEjCSprAB6jZoWEdEZF9SZLAzwKgVjtuRUT2KSkCv6Ig6OFv2d4WcSUiIokrKQK/JDcLMw3piIj0JikCf1B6GsU5WQp8EZFeJEXgA1QUKPBFRHqTNIFfnpfNlh0awxcR2ZfkCfyCbGrVwxcR2afkCfy8bBpa2mnr6Iy6FBGRhJQ0gV9REByLX9ekYR0Rkb1JmsAv09m2IiK9SprAr9gd+Orhi4jsTdIEvq6nIyLSu6QJ/KFDBpGZnsYWBb6IyF4lTeCbGWX5WdRqSEdEZK+SJvAhGMfXvW1FRPYuqQK/XPe2FRHZp7gHvpmlm9nrZvZIvJdVnp+te9uKiOxDf/Tw/xFY0g/LoTw/i5b2TprbOvpjcSIiA0pcA9/MRgAfB34Xz+V06z40U+P4IiIfFO8e/n8D3wS69jWDmV1pZtVmVl1XV3dIC+sOfF1ETUTkg+IW+GZ2JlDr7gt6m8/db3L3me4+s7S09JCW2X1vW+24FRH5oHj28D8EnG1ma4A/Aaea2Z1xXF6PIR0diy8isqe4Bb67f8vdR7h7FXAB8JS7Xxyv5QHkZGWQl5WhyyuIiOxFUh2HDzCyaAir61uiLkNEJOH0S+C7+zx3P7M/ljW5Io+lW3b0x6JERAaUpOvhTx6WR82ONhpb26MuRUQkoSRd4E+qyAdg6ZamiCsREUksSRf4kyvyAFimwBcReZ+kC/yyvCwKhwzSOL6IyB6SLvDNjEnleRrSERHZQ9IFPsCUYfks39JEV5dHXYqISMJIysCfVJFHS3snGxvfjboUEZGEkbSBD7Bks8bxRUS6JWXgTyzXkToiIntKysDPzcpgZNFgltYo8EVEuiVl4ANMrshXD19EpIckDvw8Vte3sHNXZ9SliIgkhKQN/EkVeXR2OStqm6MuRUQkISRt4OsSCyIi75e0gV9VnENmRhrLtONWRARI4sDPSE9jUnkeb23YHnUpIiIJIWkDH+CYqiJeW7eNtg7tuBURSerAnz22iLaOLt5UL19EJMkDf0wRZvDyyoaoSxERiVxSB37hkEwmV+Tz8moFvohIUgc+BL38BWu30d7RFXUpIiKRSvrAP3ZsMTt3dfHmhsaoSxERiVTSB/7sMUUAvLxKwzoiktqSPvCH5mQyuSKPl1dtjboUEZFIJX3gQzCsU712q8bxRSSlpUjgF7FzVxdvbdQ4voikrpQI/FljigE0rCMiKS0lAr8oHMd/cWV91KWIiEQmJQIfYM6kUuav2sr21l1RlyIiEomUCfyPTR9GR5fz5NKaqEsREYlEygT+4cMLGFaQzd/e3hJ1KSIikUiZwE9LMz46rYJnltfR0tYRdTkiIv0uZQIf4KPTKmjr6OKZ5XVRlyIi0u9SKvCPqRpKUU6mhnVEJCXFLfDNLNvMXjGzN8xskZn9R7yWFauM9DQ+PKWcp5bW6i5YIpJy4tnDbwNOdfcjgCOBuWZ2bByXF5O5h1XQ3NbBiyt0MTURSS1xC3wPNIc/DgofHq/lxer4ccXkZWVoWEdEUk5cx/DNLN3MFgK1wOPuPn8v81xpZtVmVl1XF/+dqVkZ6Zw2pYy/vr2Znbs0rCMiqSOuge/une5+JDACmGVm0/cyz03uPtPdZ5aWlsaznN3OnzmSHTs71MsXkZTSL0fpuHsjMA+Y2x/L259jxxYzungId7+yLupSRET6TTyP0ik1s8Lw+WDgdGBpvJZ3INLSjPNnjmT+6q2sqmve/xtERJJAPHv4w4CnzexN4FWCMfxH4ri8A/KpGSNITzPuqV4fdSkiIv0iI14f7O5vAkfF6/MPVVl+NqdOLuP+BRv4p49MYlB6Sp2DJiIpKKVT7sJZI6lvbufJJbqCpogkv5QO/DkTy6jIz+buVzSsIyLJL6UDPz3NuGDWSJ5ZXseK2qaoyxERiauUDnyAS4+rIntQGjc+syrqUkRE4irlA78oJ5NPzxzJgws3snn7u1GXIyISNykf+ACfP3EsXQ63Pr866lJEROJGgQ+MLBrCmYcP467563STcxFJWgr80BdPGkdLeyd3zl8bdSkiInGhwA9NrcxnzsRSfv/Calrbdc9bEUk+CvwevnraBOqb2zWWLyJJSYHfw4zRQ/nI1HJueGYVW1vaoy5HRKRP7Tfww3vTnmdmvzSz+8zsdjP7pplN648C+9s3506itb2D659eEXUpIiJ9qtfAN7PvAi8AxwHzgRuBe4EO4Edm9riZHR7vIvvT+LI8zpsxgjteWsuGba1RlyMi0mf2d7XMV939u/uY9nMzKwNG9W1J0fva6RN5cOEmfvH4O1x7/hFRlyMi0id67eG7+/9CMKyz5zQzK3H3WnevjldxUaksHMzlx1fxwOsbeHNDY9TliIj0iVh32r5qZsd2/2BmnwRejE9JieHLp46nJDeLf3vwbTq7POpyREQOWayBfxFwnZn91Mz+CHwBODV+ZUUvP3sQ3/74FN7YsF33vhWRpBBT4Lv7W8APgC8BpwBfcfcN8SwsEZx9RCXHjS3mp48to765LepyREQOSUyBb2a3AF8DDgcuBx42sy/Hs7BEYGb857nTaG3v4Ed/TYj7r4uIHLRYh3TeBk5x99Xu/hhwLHB0/MpKHOPL8vj8iWP584INvLCiPupyREQOWqxDOr9wd+/x83Z3vyJ+ZSWWfzxtAmNLc/jmn99kx05dTVNEBqb9nXj1sJmdZWaD9jJtrJl9z8w+F7/yEkP2oHSu/dQRbN7+Lt9/ZHHU5YiIHJT99fC/AJwILDWzV83sUTN7ysxWEZx1u8Ddb417lQngqFFDuerkcdxbvYEnl9REXY6IyAGzHiM1vc9oVgUMA94Flrt7n193YObMmV5dnbjncbV1dHLOr1+goaWdx752EkU5mVGXJCIpzswWuPvMWOaN+WqZ7r7G3V9y94XxCPuBICsjnZ+ffyTbW3fx9XsX0qUTskRkAIn1sMwmM9uxx2O9mf2PmY2Nd5GJZGplPv921lTmLavjxmdXRV2OiEjM9nfxtG4/BzYBdwEGXABUAMuAW4GT41Fcorp49ijmr2rgZ39fxsyqoRxTVRR1SSIi+xXrkM5cd7/R3ZvcfYe73wSc4e73AEPjWF9CMjN++H8OY+TQwVx91+s06CxcERkAYg38LjM738zSwsf5Paal5EB2XvYgrv/M0WxrbeeqO1+jvaMr6pJERHoVa+B/BrgEqA0flwAXm9lg4Ctxqi3hTass4CfnHc4ra7bynYfeJtYjnkREohDTGL67rwLO2sfk5/uunIHnnCOHs7ymieufXsnkinwuO74q6pJERPYq1qN0RoRH5NSaWY2Z3W9mI+Jd3EDxjQ9P4sNTy/neI4t5Znld1OWIiOxVrEM6vwceAiqB4cDD4WsCpKUZv/j0kUwsz+OqOxfw1obtUZckIvIBsQZ+qbv/3t07wscfgNI41jXg5GZlcNvlxzB0SCaX/+EV1ja0RF2SiMj7xBr49WZ2sZmlh4+LgYbe3mBmI83saTNbYmaLzOwfD73cxFaWn83tV8yio8u57NZXdNMUEUkosQb+54DzgS3AZuC88LXedADfcPcpBNfP/7KZTT3YQgeKcaW53HLZMWzZsZNLbnmFxtb2qEsSEQFivx7+Onc/291L3b3M3c9197X7ec9md38tfN4ELCEY/096M0YP5aZLZrKytplLb31F19AXkYTQ69Uyzew6ejmxyt2/GtNCgittPgtMd/cde0y7ErgSYNSoUTPWru11PTKgPLmkhi/esYAjRhZy++dmkZMV65UsRERi05dXy6wGFuzx2NTjeSzF5AL3A1/bM+wB3P0md5/p7jNLS5NrP/BpU8q57sKjWLi+kctufYUm9fRFJEK9djnd/bY9XzOz19w9pvvZhnfKuh/4o7s/cHAlDmwfO2wY1wFfvft1Lv7dfG773CwKh+g6+iLS/2K+Hn4PFtNMZgbcAixx958fxHKSxhmHDeOGi2ewZHMTF9z0so7eEZFIHEzg3xzjfB8iuObOqWa2MHyccRDLSwqnTy3nls/OZE1DC5+64SXWb03Je8iISIRivsVhf0j0Wxz2heo1W7nitmoyM9K47fJZTK3Mj7okERnA4nKLQ+kbM6uKuO9Lx5GRZnz6xpd4cWV91CWJSIpQ4EdgYnke9191PBUF2Vx6yyvc++r6qEsSkRSgwI9IZeFg/nzV8Rw3rphv3v8mP3x0iW6KLiJxpcCPUMHgQdz62WP4zOxR3PjsKq68Y4GO1ReRuFHgR2xQehrfP3c63z1rKk8vq+Xc619gZV1z1GWJSBJS4CcAM+OzHxrDnVfMprF1F+f++gUeX1wTdVkikmQU+AnkuHHFPHT1CYwpzeELt1fzX48uYVenbo4uIn1DgZ9ghhcO5t4vHsclx47mpmdXccFNL7Op8d2oyxKRJKDAT0DZg9L5z3Onc92FR7F08w7O+NVz/O3tLVGXJSIDnAI/gZ11RCUPX30CI4cO4Ut3LuBbD7xFa3tH1GWJyAClwE9wY0tzuf+q4/ninLH86dV1nHnd8yxc3xh1WSIyACnwB4DMjDS+9bEp/PGK2exs7+STv32Ra/++jPYO7dAVkdgp8AeQ48eX8LdrTuITRw3nuqdWcM71L/D2xu1RlyUiA4QCf4DJzx7Ezz51BDdfOpP65jbOuf4Ffvy3pezc1Rl1aSKS4BT4A9SHp5bzxDVz+OTRw/ntvJWc8cvndOVNEemVAn8AKxgyiJ+cdwR3XDGLji7nopvn8/V7F9KgO2qJyF4o8JPAiRNK+fs1J/HlU8bx8BubOPXaZ7jz5bV06uqbItKDAj9JZA9K558/OplHv3oiU4bl8e0H3+ac659nwdptUZcmIglCgZ9kJpTncfcXjuW6C4+ivqmdT/72Ra65ZyGbt+vyDCKpToGfhMyMs46o5MlvzOEfTh7H/761mVN+No9fPL5cZ+qKpDAFfhLLycrgm3Mn8+TX53DalHJ++eQ7nPzTedz9yjo6dBVOkZSjwE8BI4uGcP1FR3P/VccxsmgI33rgLeb+8jkeW7QFd+3YFUkVCvwUMmN0EX/+0nHccPEMurqcL96xgE/85kVeXKHj90VSgQI/xZgZc6dX8PdrTuLHnzyMmh07ueh387no5pepXrM16vJEJI4skTbpZ86c6dXV1VGXkVJ27urkj/PX8dt5K6hvbuekiaV87fQJHD1qaNSliUgMzGyBu8+MaV4FvgC0tndw58trueGZVWxtaeeE8SVcfep4Zo8tjro0EemFAl8OWktbB3+cv5abnl1NfXMbs6qK+IdTxjFnYilmFnV5IrIHBb4csp27Orn7lXXc9OwqNm/fybTKfK46eRxzp1WQka5dPyKJQoEvfaa9o4sHF27khnkrWVXfwsiiwXz+hLF8auYIhmRmRF2eSMpT4Euf6+xyHl9cw03PruS1dY0UDB7EZ2aP4tLjqqgoyI66PJGUpcCXuKpes5XfPbeavy/eQpoZZx4+jMs/NIYjRhZGXZpIyjmQwNc2uRywmVVFzKwqYl1DK79/cTX3VW/gwYWbOHJkIZd/qIq50yvIykiPukwR2YN6+HLImnbu4v4FG7jtpbWsrm+hJDeTTx8zkotmj2Z44eCoyxNJahrSkUh0dTnPrajnjpfW8OTSWgw4dXIZF80exZyJZaSn6bBOkb6WEEM6ZnYrcCZQ6+7T47UcSRxpacaciaXMmVjK+q2t3P3KOu6t3sATS6oZXjiY82eO5PxjRjCsQL1+kSjErYdvZicBzcDtsQa+evjJp72ji8cX13D3K+t4fkU9aQZzJpby6WNGcurkcjIzdEy/yKFImCEdM6sCHlHgC8C6hlburV7PfQvWU7OjjaKcTD5x1HDOmzGCKcPyoy5PZEAaUIFvZlcCVwKMGjVqxtq1a+NWjySGjs4unltRz33V63l8cQ27Op2pw/L55IwRnHNkJSW5WVGXKDJgDKjA70k9/NSztaWdh9/YxP2vbeDNDdtJTzNOmlDCJ44ewYenlDM4U4d3ivRGgS8D0js1TTzw+kb+8vpGNm3fSU5mOh+dVsHZR1ZywvgSXcNHZC8U+DKgdXU581dv5S8LN/LoW5vZsbODopxMzjisgjMPr2RWVRFpOsRTBEiQwDezu4GTgRKgBviOu9/S23sU+LKnto5O5i2r4+E3NvHEkhp27uqiLC+LMw4bxpmHD+PoUUMV/pLSEiLwD4YCX3rT0tbBE0tqePStzTy9rI72ji4q8rOZO72CMw4bxozRQ3Vyl6QcBb4kvaadu3hySS2PvrWZecuD8C/Ny+IjU8uZO72CY8cWM0hj/pICFPiSUprbOnhqaS2Pvb2Fp5fV0treSX52BqdNKecjU8s5aWIpOVm6TqAkJwW+pKyduzp57p16Hlu0hSeW1NDYuovMjDROGF/C6VPKOX1KGWX5un6/JA8FvgjBCV6vrNnKE4treXzJFtZvfReAw0cUcNrkck6bUsa0ynzdq1cGNAW+yB7cneU1zTyxpIYnltSwcH0j7lCen8Upk8o4ZXIZHxpfQq6GfmSAUeCL7Ed9cxtPL63l6WW1PLe8nqa2DgalG7PGFHHyxDJOnlTK+LJc9f4l4SnwRQ5Ae0cX1Wu2Mm95HfOW1bK8phmAyoJs5kwq5aQJpRw/voSCwYMirlTkgxT4IodgY+O7PBuG/wsrGmhu6yDN4MiRhZw4oZQTJ5Rw5MhCXepBEoICX6SP7Ors4vV1jTz3Th3PLq/jzY3bcYe8rAxmjy3mxAklfGh8CeNKczT8I5FQ4IvESWNrOy+ubOC5d+p4fkX97iN/KvKzOX5cMcePL+H4ccVU6l6+0k8U+CL9ZF1DK8+vqOeFlfW8tLKBrS3tAIwuHsLx44o5dmwxx40t1rH/EjcKfJEIdHU5y2qaeGllAy+ubGD+6gaadnYAMLY0h2PHFjN7TBHHji2mXCsA6SMKfJEE0NnlLNq0nZdXNfDSygaq12yjqS1YAVQVD2HWmCJmjQlWAiOGDtY+ADkoCnyRBNTR2cWSzU3MX93A/NVbeWX1Vra/uwsI9gEcM6aIWVVDOWZMERPL8nTZZ4mJAl9kAOjqcpbXNvHq6q3MX72VV9dspWZHGwB52RnMGD2UmaOHMmN0EUeOLNTtHmWvDiTwdR65SETS0ozJFflMrsjnkuOqcHc2bHuXV9ds5dU124KTwZbVAZCRZkyrzOfo0UM5etRQZoweqiOB5ICphy+SwBpb23lt3Taq12xjwdptvLGhkZ27uoBgGOjo0YUcPWooR40qZFplAdmDtBWQatTDF0kShUMyOXVyOadOLgeCE8GWbN7Ba2u38dq6Rhas3cajb20BYFC6MXVYPkeOLOTIUYUcOXIoVcVDtDNYdlMPX2SAq23ayevrGnl9XSML12/jzQ3baW3vBKBwyCCOGFHIESMLOXJkAYePKKQkNyviiqUvqYcvkkLK8rL56LQKPjqtAgiOBlpe08wbGxpZuK6Rhesbee6dd+gK+3bDCwdz+Igg/I8YUcD0EQXkZ+vCcKlAPXyRFNDS1sGiTTt4Y30jb2xo5M0N21m3tXX39LElOUwfXsBhwws4bEQB0yrzydNKYEBQD19E3icnKyM80ato92vbWtp5a+N23tq4nTfWN1K9ZisPvbFp9/SxJTlMG17AYcPzmV5ZwLTKAgqGaCUwkCnwRVLU0JxMTppYykkTS3e/Vt/cxlsbtvN2uCJYsGYrD/dYCYwYOjgM/3ymDc9nWmUBZXlZ2jE8QCjwRWS3ktwsTpkc3PKxW0NzG4s27eDtTdtZtGkHizft4G+LtvR4TyZThuUztTKfqcPymVaZz5iSXNJ1pnDCUeCLSK+Kc7M+sCXQtHMXSzY3sWjTdhZv2sGiTTu49fnV7OoM9glmZaQxuSKPKcPymTIsP3hema+dwxGAV3dIAAAIiklEQVTTTlsR6RPtHV2srGtm8aYdLNm8g8Xho7F11+55hhcOZsqwPCZV5DG5Ip8pw/KoKs7R3cMOgXbaiki/y8xI292j7+bu1OxoY8mWYCWwbEsTSzbv4OlldXSGx4lmZqQxvjSXyRXBiqD7UZGfrX0DfUyBLyJxY2ZUFGRTUZDNKZPe2y/Q1tHJitpmlm1pYmn4eGFlPQ+8vnH3PPnZGUyqyGNiebACmFCWx8TyXIp14thBU+CLSL/LykhnWnioZ0/bWtpZXtPE8ppgJfBOTTMPv7GJP87v2D1PSW4mE8rymFCey4TyPCaWBf8W5WT2dzMGHAW+iCSMoTmZzB5bzOyxxbtf6x4W6l4RvFPTzPLaJh54bSPNbe+tCIpzMoOVQLgyGF+ay/jyXEpzddhoNwW+iCS0nsNCPY8Ucnc2b9/JO7XNvBOuDFbUNvPgwo27by0JwdDQ+LJcxpflMq70vX9HFg1JuUNHFfgiMiCZGZWFg6ksHMycPVYENTvaWFHbzIraJlbUNfNOTTNPLa3l3uoNu+fLTE9jTEkO48pyGFeau/sxpjSH3KzkjMbkbJWIpKyeWwQnTCh537TG1nZW1jWzsraFFXXNrKgNDiP929tbdl9cDqA8P4txpbmMLc1hbMl7/w4fOnhAbxUo8EUkZRQOyWTG6CJmjC563+ttHZ2sbWhlVV0zK+taWFnXzKq6Fh5auIkdPYaHMtPTGF08hLGlOYwpyWVsSQ5jSnMYU5JDcU5mwu8riGvgm9lc4JdAOvA7d/9RPJcnInIwsjLSmVgeHALak7vT0NLOqroWVtcHK4FV9S2srGvhqaW1u88sBsjLyqCqJAj/4N8hVBUHPxcOSYwjiOIW+GaWDlwPfBjYALxqZg+5++J4LVNEpC+ZGSW5WZTkZr3vSqMQ3HdgY+O7rK5vYVVdC2saWlhd38Jr67bx8Jub6HkRg8Ihg6gqzqGqeAhVJTlUFecwujhYIRQOGdRvWwbx7OHPAla4+yoAM/sTcA6gwBeRAS8jPY3RxTmMLs7h5Envn9bW0cn6ra2srm9lTX2wMljT0MKra7bxlzfevzLoPsHs3i8eF/fgj2fgDwfW9/h5AzB7z5nM7ErgSoBRo0bFsRwRkf6RlZHO+LI8xpflfWBa98pgbUMraxpaWdvQQntHV7/08uMZ+Hur/gNXanP3m4CbILh4WhzrERGJXG8rg3iL5yXqNgAje/w8Ati0j3lFRCTO4hn4rwITzGyMmWUCFwAPxXF5IiLSi7gN6bh7h5l9BXiM4LDMW919UbyWJyIivYvrcfju/ijwaDyXISIisdFtZkREUoQCX0QkRSjwRURShAJfRCRFmHvinOtkZnXA2gN4SwlQH6dyElUqthlSs92p2GZIzXYfSptHu3vp/mdLsMA/UGZW7e4zo66jP6VimyE1252KbYbUbHd/tVlDOiIiKUKBLyKSIgZ64N8UdQERSMU2Q2q2OxXbDKnZ7n5p84AewxcRkdgN9B6+iIjESIEvIpIiEj7wzWyumS0zsxVm9q97mZ5lZveE0+ebWVX/V9n3Ymj3181ssZm9aWZPmtnoKOrsS/trc4/5zjMzN7OkOHQvlnab2fnh73uRmd3V3zX2tRj+vkeZ2dNm9nr4N35GFHX2JTO71cxqzeztfUw3M/tV+J28aWZH93kR7p6wD4LLKq8ExgKZwBvA1D3m+QfghvD5BcA9UdfdT+0+BRgSPr9qoLc7ljaH8+UBzwIvAzOjrrufftcTgNeBoeHPZVHX3Q9tvgm4Knw+FVgTdd190O6TgKOBt/cx/QzgrwR3CzwWmN/XNSR6D3/3jdDdvR3ovhF6T+cAt4XP/wycZv11C/j42W+73f1pd28Nf3yZ4I5iA1ksv2uA/wR+Auzsz+LiKJZ2fwG43t23Abh7bT/X2NdiabMD+eHzApLgbnnu/iywtZdZzgFu98DLQKGZDevLGhI98Pd2I/Th+5rH3TuA7UBxv1QXP7G0u6crCHoGA9l+22xmRwEj3f2R/iwszmL5XU8EJprZC2b2spnN7bfq4iOWNn8XuNjMNhDcU+Pq/iktUgf6//6AxfUGKH0glhuhx3Sz9AEm5jaZ2cXATGBOXCuKv17bbGZpwC+Az/ZXQf0klt91BsGwzskEW3LPmdl0d2+Mc23xEkubLwT+4O7XmtlxwB1hm7viX15k4p5lid7Dj+VG6LvnMbMMgs2/3jabBoKYbgBvZqcD/w84293b+qm2eNlfm/OA6cA8M1tDMMb5UBLsuI31b/wv7r7L3VcDywhWAANVLG2+ArgXwN1fArIJLjCWzGL6f38oEj3wY7kR+kPAZeHz84CnPNwDMoDtt93h8MaNBGE/0Md0YT9tdvft7l7i7lXuXkWw3+Jsd6+Optw+E8vf+IMEO+kxsxKCIZ5V/Vpl34qlzeuA0wDMbApB4Nf1a5X97yHg0vBonWOB7e6+uS8XkNBDOr6PG6Gb2feAand/CLiFYHNvBUHP/oLoKu4bMbb7p0AucF+4j3qdu58dWdGHKMY2J50Y2/0Y8BEzWwx0Av/s7g3RVX1oYmzzN4CbzewagmGNzw70jpyZ3U0wLFcS7pv4DjAIwN1vINhXcQawAmgFLu/zGgb4dygiIjFK9CEdERHpIwp8EZEUocAXEUkRCnwRkRShwBcRSREKfBGRFKHAFxFJEQp8kX0ws2PC65Jnm1lOeC366VHXJXKwdOKVSC/M7PsEp/UPBja4+w8jLknkoCnwRXoRXuvlVYLr7x/v7p0RlyRy0DSkI9K7IoJrFuUR9PRFBiz18EV6YWYPEdyRaQwwzN2/EnFJIgctoa+WKRIlM7sU6HD3u8wsHXjRzE5196eirk3kYKiHLyKSIjSGLyKSIhT4IiIpQoEvIpIiFPgiIilCgS8ikiIU+CIiKUKBLyKSIv4/AyXAUOzbGgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, -y)\n",
    "plt.title(\"Negative Log Likelihood Curve\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('-log(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [discussion](https://stats.stackexchange.com/questions/141087/i-am-wondering-why-we-use-negative-log-likelihood-sometimes) and this [blog post](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Restricted Boltzmann Machines (RBMs) <a class=\"anchor\" id=\"rbm_concepts\"></a> \n",
    "[To Top](#toc)\n",
    "- http://deeplearning.net/tutorial/rbm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"http://deeplearning.net/tutorial/rbm.html#view=FitH\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b668908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"http://deeplearning.net/tutorial/rbm.html#view=FitH\", width=PDF_W, height=PDF_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy-Based Models (EBM)\n",
    "> EBMs associate a scalar energy to each configuration of the variables of interest. Learning corresponds to modifying that energy function so that its shape has desirable properties. For example, we would like plausible or desirable configurations to have low energy. \n",
    "\n",
    "Energy-based probabilistic models define a probability distribution through an energy function:\n",
    "\n",
    "\\begin{equation} \\tag{1}\n",
    "p(x) = \\frac{e^{-E(x)}}{Z}\n",
    "\\end{equation}\n",
    "\n",
    "where $x$ is the *state*, $E(x)$ is the *energy function*, and $Z$ is the *partition function* defined as:\n",
    "\n",
    "$$ Z = \\sum_x e^{-E(x)}$$\n",
    "\n",
    "##### Learning\n",
    "The EBM can be learned via stochastic gradient descent on the empirical *[negative log-likelihood](#NLL)*.\n",
    "\n",
    "\n",
    "\n",
    "Let the log-likelihood be defined as:\n",
    "\n",
    "$$ \\mathcal{L}(\\theta, \\mathcal{D}) = \\frac{1}{N} \\sum_{x^{(i)} \\in \\mathcal{D}} \\log p\\left(x^{(i)}\\right)$$\n",
    "\n",
    "<pre> x = 5</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Attractors of Discrete-Time Recurrent Neural Networks\n",
    "- Yu, Jiali, et al. (2012)\n",
    "- https://sci-hub.tw/10.1007/s00521-012-0975-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- RNNs can possess more than one and even infinite stable equilibrium points.\n",
    " - These points may be isolated (discrete) or connected (continuous)\n",
    " - Continuous attractors have been used to describe the encoding of continuous stimuli such as eye position, head direction, moving direction, path integrator, cognitive map, and population decoding.\n",
    "- In these networks, RNNs may have a finite number of neurons or infinite number of neurons.\n",
    " - These two categories of RNN differ in their dynamics, from a mathematical point of view.\n",
    " \n",
    "- This paper focuses on continuous attractors with finite number of neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Dynamics in Attractor Networks\n",
    "- Li, Quoqi, et al. (2015)\n",
    "- https://pdfs.semanticscholar.org/840c/a6d4434de3dac8cf13dff6d4bcbbc2164922.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Propose a new energy function that is nonnegative and attains zero values only at the desired memory patterns.\n",
    "- Following from the contrived energy function, an attractor network is derived. This approach avoids the existence of spurious points (local maxima, saddle points, or other local minima which are undesired memory patters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
